{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Setting up directories and imnporting data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set up base path to training data directory\n",
        "training_path = os.path.join(os.getcwd(), 'data', 'training')\n",
        "\n",
        "# Set up paths to all training CSV files\n",
        "training_calendar_path = os.path.join(training_path, 'calendar.csv')\n",
        "training_product_details_path = os.path.join(training_path, 'product_details_train.csv')\n",
        "training_promotion_details_path = os.path.join(training_path, 'promotion_details_train.csv')\n",
        "training_transactions_path = os.path.join(training_path, 'transactions_train.csv')\n",
        "training_weather_path = os.path.join(training_path, 'weather_data.csv')\n",
        "\n",
        "# Set up base path to forecasting data directory\n",
        "forecast_path = os.path.join(os.getcwd(), 'data', 'forecasting')\n",
        "\n",
        "# Set up paths to all 4 forecasting CSV files\n",
        "forecast_calendar_path = os.path.join(forecast_path, 'forecast_calendar.csv')\n",
        "forecast_product_details_path = os.path.join(forecast_path, 'forecast_product_details.csv')\n",
        "forecast_promotion_details_path = os.path.join(forecast_path, 'forecast_promotion_details.csv')\n",
        "forecast_transactions_path = os.path.join(forecast_path, 'forecast_transactions.csv')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Importing training data\n",
        "df_calendar_train = pd.read_csv(training_calendar_path, sep=',', engine='python')\n",
        "df_product_train = pd.read_csv(training_product_details_path, sep=';', engine='python')\n",
        "df_promotion_train = pd.read_csv(training_promotion_details_path, sep=';', engine='python', decimal=',')\n",
        "df_transactions_train = pd.read_csv(training_transactions_path, sep=';', engine='python', decimal=',')\n",
        "df_weather_train = pd.read_csv(training_weather_path, sep=',', engine='python')\n",
        "\n",
        "# Importing forecasting data\n",
        "df_calendar_forecast = pd.read_csv(forecast_calendar_path, sep=';', engine='python')\n",
        "df_product_forecast = pd.read_csv(forecast_product_details_path, sep=';', engine='python')\n",
        "df_promotion_forecast = pd.read_csv(forecast_promotion_details_path, sep=';', engine='python')\n",
        "df_transactions_forecast = pd.read_csv(forecast_transactions_path, sep=';', engine='python')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "mapping = {'J': 1, 'N': 0}\n",
        "\n",
        "df_calendar_train['date'] = pd.to_datetime(df_calendar_train['date'])\n",
        "df_calendar_train['holidayEventIndicator'] = df_calendar_train['holidayEventIndicator'].map(mapping)\n",
        "df_calendar_train['workingDayIndicator'] = df_calendar_train['workingDayIndicator'].map(mapping)\n",
        "df_calendar_train = df_calendar_train.convert_dtypes()\n",
        "\n",
        "df_calendar_forecast['date'] = pd.to_datetime(df_calendar_forecast['date'])\n",
        "df_calendar_forecast['holidayEventIndicator'] = df_calendar_forecast['holidayEventIndicator'].map(mapping)\n",
        "df_calendar_forecast['workingDayIndicator'] = df_calendar_forecast['workingDayIndicator'].map(mapping)\n",
        "df_calendar_forecast = df_calendar_forecast.convert_dtypes()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1461 entries, 0 to 1460\n",
            "Data columns (total 5 columns):\n",
            " #   Column                 Non-Null Count  Dtype         \n",
            "---  ------                 --------------  -----         \n",
            " 0   date                   1461 non-null   datetime64[ns]\n",
            " 1   holidayEventIndicator  1461 non-null   Int64         \n",
            " 2   workingDayIndicator    1461 non-null   Int64         \n",
            " 3   holidayEventName       63 non-null     string        \n",
            " 4   doWName                1461 non-null   string        \n",
            "dtypes: Int64(2), datetime64[ns](1), string(2)\n",
            "memory usage: 60.1 KB\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 31 entries, 0 to 30\n",
            "Data columns (total 5 columns):\n",
            " #   Column                 Non-Null Count  Dtype         \n",
            "---  ------                 --------------  -----         \n",
            " 0   date                   31 non-null     datetime64[ns]\n",
            " 1   holidayEventIndicator  31 non-null     Int64         \n",
            " 2   workingDayIndicator    31 non-null     Int64         \n",
            " 3   holidayEventName       3 non-null      string        \n",
            " 4   doWName                31 non-null     string        \n",
            "dtypes: Int64(2), datetime64[ns](1), string(2)\n",
            "memory usage: 1.4 KB\n"
          ]
        }
      ],
      "source": [
        "df_calendar_train.info()\n",
        "df_calendar_forecast.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['station_id',\n",
              " 'date',\n",
              " 'mean_wind_dir',\n",
              " 'mean_wind_speed_vec',\n",
              " 'mean_wind_speed',\n",
              " 'max_hourly_wind',\n",
              " 'hour_max_wind',\n",
              " 'min_hourly_wind',\n",
              " 'hour_min_wind',\n",
              " 'max_gust',\n",
              " 'hour_max_gust',\n",
              " 'mean_temp',\n",
              " 'min_temp',\n",
              " 'hour_min_temp',\n",
              " 'max_temp',\n",
              " 'hour_max_temp',\n",
              " 'min_temp_10cm',\n",
              " 'hour_min_temp_10cm',\n",
              " 'sunshine_hours',\n",
              " 'sunshine_percent',\n",
              " 'solar_radiation',\n",
              " 'precip_duration',\n",
              " 'rel_humidity',\n",
              " 'max_rel_humidity',\n",
              " 'hour_max_rel_humidity',\n",
              " 'mean_pressure',\n",
              " 'max_pressure',\n",
              " 'hour_max_pressure',\n",
              " 'min_pressure',\n",
              " 'hour_min_pressure',\n",
              " 'min_visibility',\n",
              " 'hour_min_visibility',\n",
              " 'max_visibility',\n",
              " 'hour_max_visibility',\n",
              " 'cloud_cover',\n",
              " 'mean_abs_humidity',\n",
              " 'max_abs_humidity',\n",
              " 'hour_max_abs_humidity',\n",
              " 'min_abs_humidity',\n",
              " 'hour_min_abs_humidity',\n",
              " 'evaporation_24h']"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Renaming weather dataframe\n",
        "rename_map = {\n",
        "    'STN':'station_id',\n",
        "    'YYYYMMDD':'date',\n",
        "    'DDVEC':'mean_wind_dir',\n",
        "    'FHVEC':'mean_wind_speed_vec',\n",
        "    'FG':'mean_wind_speed',\n",
        "    'FHX':'max_hourly_wind',\n",
        "    'FHXH':'hour_max_wind',\n",
        "    'FHN':'min_hourly_wind',\n",
        "    'FHNH':'hour_min_wind',\n",
        "    'FXX':'max_gust',\n",
        "    'FXXH':'hour_max_gust',\n",
        "    'TG':'mean_temp',\n",
        "    'TN':'min_temp',\n",
        "    'TNH':'hour_min_temp',\n",
        "    'TX':'max_temp',\n",
        "    'TXH':'hour_max_temp',\n",
        "    'T10N':'min_temp_10cm',\n",
        "    'T10NH':'hour_min_temp_10cm',\n",
        "    'SQ':'sunshine_hours',\n",
        "    'SP':'sunshine_percent',\n",
        "    'Q':'solar_radiation',\n",
        "    'DR':'precip_duration',\n",
        "    'RH':'rel_humidity',\n",
        "    'RHX':'max_rel_humidity',\n",
        "    'RHXH':'hour_max_rel_humidity',\n",
        "    'PG':'mean_pressure',\n",
        "    'PX':'max_pressure',\n",
        "    'PXH':'hour_max_pressure',\n",
        "    'PN':'min_pressure',\n",
        "    'PNH':'hour_min_pressure',\n",
        "    'VVN':'min_visibility',\n",
        "    'VVNH':'hour_min_visibility',\n",
        "    'VVX':'max_visibility',\n",
        "    'VVXH':'hour_max_visibility',\n",
        "    'NG':'cloud_cover',\n",
        "    'UG':'mean_abs_humidity',\n",
        "    'UX':'max_abs_humidity',\n",
        "    'UXH':'hour_max_abs_humidity',\n",
        "    'UN':'min_abs_humidity',\n",
        "    'UNH':'hour_min_abs_humidity',\n",
        "    'EV24':'evaporation_24h'\n",
        "}\n",
        "\n",
        "df_weather_train = df_weather_train.rename(columns=lambda c: rename_map.get(c.strip(), c.strip())\n",
        ")\n",
        "\n",
        "list(df_weather_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 1461 entries, 43830 to 45290\n",
            "Data columns (total 41 columns):\n",
            " #   Column                 Non-Null Count  Dtype         \n",
            "---  ------                 --------------  -----         \n",
            " 0   station_id             1461 non-null   int64         \n",
            " 1   date                   1461 non-null   datetime64[ns]\n",
            " 2   mean_wind_dir          1461 non-null   int64         \n",
            " 3   mean_wind_speed_vec    1461 non-null   int64         \n",
            " 4   mean_wind_speed        1461 non-null   int64         \n",
            " 5   max_hourly_wind        1461 non-null   int64         \n",
            " 6   hour_max_wind          1461 non-null   int64         \n",
            " 7   min_hourly_wind        1461 non-null   int64         \n",
            " 8   hour_min_wind          1461 non-null   int64         \n",
            " 9   max_gust               1461 non-null   int64         \n",
            " 10  hour_max_gust          1461 non-null   int64         \n",
            " 11  mean_temp              1461 non-null   int64         \n",
            " 12  min_temp               1461 non-null   int64         \n",
            " 13  hour_min_temp          1461 non-null   int64         \n",
            " 14  max_temp               1461 non-null   int64         \n",
            " 15  hour_max_temp          1461 non-null   int64         \n",
            " 16  min_temp_10cm          1461 non-null   int64         \n",
            " 17  hour_min_temp_10cm     1461 non-null   int64         \n",
            " 18  sunshine_hours         1461 non-null   int64         \n",
            " 19  sunshine_percent       1461 non-null   int64         \n",
            " 20  solar_radiation        1461 non-null   int64         \n",
            " 21  precip_duration        1461 non-null   int64         \n",
            " 22  rel_humidity           1461 non-null   int64         \n",
            " 23  max_rel_humidity       1461 non-null   int64         \n",
            " 24  hour_max_rel_humidity  1461 non-null   int64         \n",
            " 25  mean_pressure          1461 non-null   int64         \n",
            " 26  max_pressure           1461 non-null   int64         \n",
            " 27  hour_max_pressure      1461 non-null   int64         \n",
            " 28  min_pressure           1461 non-null   int64         \n",
            " 29  hour_min_pressure      1461 non-null   int64         \n",
            " 30  min_visibility         1461 non-null   int64         \n",
            " 31  hour_min_visibility    1461 non-null   int64         \n",
            " 32  max_visibility         1461 non-null   int64         \n",
            " 33  hour_max_visibility    1461 non-null   int64         \n",
            " 34  cloud_cover            1461 non-null   int64         \n",
            " 35  mean_abs_humidity      1461 non-null   int64         \n",
            " 36  max_abs_humidity       1461 non-null   int64         \n",
            " 37  hour_max_abs_humidity  1461 non-null   int64         \n",
            " 38  min_abs_humidity       1461 non-null   int64         \n",
            " 39  hour_min_abs_humidity  1461 non-null   int64         \n",
            " 40  evaporation_24h        1461 non-null   int64         \n",
            "dtypes: datetime64[ns](1), int64(40)\n",
            "memory usage: 479.4 KB\n"
          ]
        }
      ],
      "source": [
        "df_weather_train['date'] = pd.to_datetime(df_weather_train['date'].astype(str), format='%Y%m%d')\n",
        "df_weather_train = df_weather_train[(df_weather_train['date'].dt.year >= 2021) & (df_weather_train['date'].dt.year <= 2024)]\n",
        "for col in df_weather_train.select_dtypes(include='object').columns:\n",
        "    df_weather_train[col] = pd.to_numeric(df_weather_train[col], errors='coerce')\n",
        "\n",
        "df_weather_train.info()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 6290 entries, 0 to 6575\n",
            "Data columns (total 3 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   promo_id     6290 non-null   string \n",
            " 1   articleId    6290 non-null   string \n",
            " 2   discountPct  6290 non-null   Float64\n",
            "dtypes: Float64(1), string(2)\n",
            "memory usage: 202.7 KB\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 247 entries, 0 to 246\n",
            "Data columns (total 3 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   promo_id     247 non-null    string \n",
            " 1   articleId    247 non-null    string \n",
            " 2   discountPct  247 non-null    Float64\n",
            "dtypes: Float64(1), string(2)\n",
            "memory usage: 6.2 KB\n"
          ]
        }
      ],
      "source": [
        "# Remove row with the problematic value\n",
        "df_promotion_train = df_promotion_train[df_promotion_train['discountPct'] != \"1.000.000.003\"]\n",
        "\n",
        "df_promotion_train['discountPct'] = pd.to_numeric(df_promotion_train['discountPct'])\n",
        "# Dropping rows with null discountPct - We cant do anything with them\n",
        "df_promotion_train = df_promotion_train.dropna(subset=['discountPct'])\n",
        "df_promotion_train = df_promotion_train.convert_dtypes()\n",
        "df_promotion_train.info()\n",
        "\n",
        "df_promotion_forecast['discountPct'] = pd.to_numeric(df_promotion_forecast['discountPct'])\n",
        "df_promotion_forecast = df_promotion_forecast.convert_dtypes()\n",
        "df_promotion_forecast.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 343849 entries, 0 to 343848\n",
            "Data columns (total 6 columns):\n",
            " #   Column              Non-Null Count   Dtype         \n",
            "---  ------              --------------   -----         \n",
            " 0   date                343849 non-null  datetime64[ns]\n",
            " 1   articleId           343849 non-null  string        \n",
            " 2   storeCount          343849 non-null  Int64         \n",
            " 3   FSC_index           343831 non-null  Float64       \n",
            " 4   sales_volume_index  343849 non-null  Float64       \n",
            " 5   promo_id            46012 non-null   string        \n",
            "dtypes: Float64(2), Int64(1), datetime64[ns](1), string(2)\n",
            "memory usage: 16.7 MB\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 7579 entries, 0 to 7578\n",
            "Data columns (total 6 columns):\n",
            " #   Column              Non-Null Count  Dtype         \n",
            "---  ------              --------------  -----         \n",
            " 0   date                7579 non-null   datetime64[ns]\n",
            " 1   articleId           7579 non-null   string        \n",
            " 2   storeCount          7579 non-null   Int64         \n",
            " 3   FSC_index           7579 non-null   Float64       \n",
            " 4   sales_volume_index  0 non-null      Int64         \n",
            " 5   promo_id            1558 non-null   string        \n",
            "dtypes: Float64(1), Int64(2), datetime64[ns](1), string(2)\n",
            "memory usage: 377.6 KB\n"
          ]
        }
      ],
      "source": [
        "df_transactions_train['date']  = pd.to_datetime(df_transactions_train['date'], format='%d-%m-%Y')\n",
        "df_transactions_train = df_transactions_train.convert_dtypes()\n",
        "df_transactions_train.info()\n",
        "\n",
        "df_transactions_forecast['date']  = pd.to_datetime(df_transactions_forecast['date'], format='%d-%m-%Y')\n",
        "df_transactions_forecast = df_transactions_forecast.convert_dtypes()\n",
        "df_transactions_forecast.info()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Merging the dataframes into one"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "master training dataset shape: (343849, 53)\n",
            "master forecast dataset shape: (7579, 13)\n"
          ]
        }
      ],
      "source": [
        "df_master_train = df_transactions_train.copy()\n",
        "\n",
        "df_master_train = df_master_train.merge(\n",
        "    df_promotion_train,\n",
        "    on=['promo_id', 'articleId'],\n",
        "    how='left',\n",
        "    validate='m:1' \n",
        ")\n",
        "\n",
        "df_master_train = df_master_train.merge(\n",
        "    df_product_train,\n",
        "    left_on='articleId',\n",
        "    right_on='articleId',\n",
        "    how='left',\n",
        "    validate='m:1'\n",
        ")\n",
        "\n",
        "df_master_train = df_master_train.merge(\n",
        "    df_calendar_train,\n",
        "    on='date',\n",
        "    how='left',\n",
        "    validate='m:1'\n",
        ")\n",
        "\n",
        "df_master_train = df_master_train.merge(\n",
        "    df_weather_train,\n",
        "    on='date',\n",
        "    how='left',\n",
        "    validate='m:1'\n",
        ")\n",
        "\n",
        "print(f\"master training dataset shape: {df_master_train.shape}\")\n",
        "\n",
        "\n",
        "df_master_forecast = df_transactions_forecast.copy()\n",
        "\n",
        "df_master_forecast = df_master_forecast.merge(\n",
        "    df_promotion_forecast,\n",
        "    on=['promo_id', 'articleId'],\n",
        "    how='left',\n",
        "    validate='m:1' \n",
        ")\n",
        "\n",
        "df_master_forecast = df_master_forecast.merge(\n",
        "    df_product_forecast,\n",
        "    left_on='articleId',\n",
        "    right_on='articleId',\n",
        "    how='left',\n",
        "    validate='m:1'\n",
        ")\n",
        "\n",
        "df_master_forecast = df_master_forecast.merge(\n",
        "    df_calendar_forecast,\n",
        "    on='date',\n",
        "    how='left',\n",
        "    validate='m:1'\n",
        ")\n",
        "\n",
        "print(f\"master forecast dataset shape: {df_master_forecast.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save merged dataframes to CSV files\n",
        "merged_data_path = os.path.join(os.getcwd(), 'data', 'merged_data')\n",
        "os.makedirs(merged_data_path, exist_ok=True)\n",
        "\n",
        "# Save training master dataset\n",
        "master_train_path = os.path.join(merged_data_path, 'master_train.csv')\n",
        "df_master_train.to_csv(master_train_path, index=False)\n",
        "print(f\"Saved master training dataset to: {master_train_path}\")\n",
        "print(f\"Shape: {df_master_train.shape}\")\n",
        "\n",
        "# Save forecast master dataset\n",
        "master_forecast_path = os.path.join(merged_data_path, 'master_forecast.csv')\n",
        "df_master_forecast.to_csv(master_forecast_path, index=False)\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (myenv)",
      "language": "python",
      "name": "myenv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
